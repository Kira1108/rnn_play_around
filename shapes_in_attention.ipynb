{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine translation pseudo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huan/anaconda/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, LSTM, Activation, Dot, Embedding, Lambda, Bidirectional, RepeatVector\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = lambda *x: Model(*x).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 100\n",
    "Ty = 80\n",
    "Dx = 100\n",
    "Dy = 50\n",
    "Vx = 10000\n",
    "Vy = 15000\n",
    "Mx = 25\n",
    "My = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "en_seq_in (InputLayer)       [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "en_seq_embd (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "en_lstm (Bidirectional)      (None, 100, 50)           25200     \n",
      "=================================================================\n",
      "Total params: 1,025,200\n",
      "Trainable params: 1,025,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = Input(shape = (Tx,), name = 'en_seq_in')\n",
    "encoder_embedding = Embedding(Vx, Dx, input_length = Tx, name = 'en_seq_embd')\n",
    "encoder_lstm = Bidirectional(LSTM(Mx,return_sequences = True), name = 'en_lstm')\n",
    "x = encoder_embedding(encoder_input)\n",
    "encoder_output = encoder_lstm(x)\n",
    "\n",
    "model_test(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 80)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 80, 50)            750000    \n",
      "=================================================================\n",
      "Total params: 750,000\n",
      "Trainable params: 750,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_tf_input = Input(shape = (Ty,))\n",
    "decoder_embedding_layer = Embedding(Vy, Dy, input_length = Ty)\n",
    "decoder_tfembd_input = decoder_embedding_layer(decoder_tf_input)\n",
    "\n",
    "model_test(decoder_tf_input, decoder_tfembd_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape reminder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 10, 20)            2000      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional [(None, 10, 60), (None, 3 12240     \n",
      "=================================================================\n",
      "Total params: 14,240\n",
      "Trainable params: 14,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "h1, h2 has shapes: (3, 30), (3, 30)\n",
      "c1, c2 has shapes: (3, 30), (3, 30)\n",
      "o has a shape: (3, 10, 60)\n"
     ]
    }
   ],
   "source": [
    "def remind():\n",
    "    ins = Input(shape = (10,))\n",
    "    x = Embedding(100, 20, input_length = 10)(ins)\n",
    "    o,h1,h2,c1,c2 = Bidirectional(LSTM(30, return_sequences = True, return_state = True))(x)\n",
    "    test_model = Model(ins, [o,h1,h2,c1,c2])\n",
    "\n",
    "    test_model.summary()\n",
    "\n",
    "    x_in = np.random.randint(1,100,size = (3,10))\n",
    "    o,h1,h2,c1,c2 = test_model.predict(x_in)\n",
    "\n",
    "    print('h1, h2 has shapes: {}, {}'.format(h1.shape, h2.shape))\n",
    "    print('c1, c2 has shapes: {}, {}'.format(c1.shape, c2.shape))\n",
    "    print('o has a shape: {}'.format(o.shape))\n",
    "    \n",
    "remind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def softmax_over_time(x):\n",
    "    # (batch, time, hidden), at least 3 dimensions\n",
    "    assert(K.ndim(x) > 2)\n",
    "    \n",
    "    e = K.exp(x - K.max(x, axis = -1, keepdims = True))\n",
    "    s = K.sum(e, axis = -1, keepdims = True)\n",
    "    return e/s\n",
    "\n",
    "\n",
    "attn_repeat_layer = RepeatVector(Tx)\n",
    "attn_concat_layer = Concatenate(axis = -1)\n",
    "attn_dense1 = Dense(10, activation = 'tanh')\n",
    "attn_dense2 = Dense(1, activation = softmax_over_time)\n",
    "attn_dot = Dot(axes = 1)\n",
    "\n",
    "\n",
    "def one_step_attention(h, st_1):\n",
    "    '''\n",
    "        h          size  (batch, Tx, 2Mx)\n",
    "        st_1       size  (batch, 1,  My)\n",
    "        st_1_rpt   size  (batch, Tx, My)\n",
    "        st_1_h     size  (batch, Tx, My + 2Mx)\n",
    "        alpha_1    size  (batch, Tx, 10)\n",
    "        alpha_2    size  (batch, Tx, 1)\n",
    "        context    size  (batch, 1,  2Mx) - something like 1 step of h\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    st_1_rpt = attn_repeat_layer(st_1)\n",
    "    st_1_h = attn_concat_layer([st_1_rpt,h])\n",
    "    alphas = attn_dense1(st_1_h)\n",
    "    alphas = attn_dense2(alphas)\n",
    "    context = attn_dot([alphas, h])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(My,return_state = True)\n",
    "decoder_dense = Dense(Vy, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building blocks\n",
    "\n",
    "\n",
    "1. Encoder input token sequences -> Encoder ouput sequence of hidden vectors              \n",
    "2. Decoder input teaching forcing - Decoder input embedded teaching forcing sequences            \n",
    "3. One step attention,               \n",
    "    takes inputs of all hidden vector for all time steps of encoder(done)               \n",
    "    and previous decoder hidden states(initialize first step with 0, and pass on)                                \n",
    "    output a context vector, which is a vector, for current timestep(done.)\n",
    "    \n",
    "4. pass decoder s & c as hidden and cell states,                \n",
    "    decoder input = concat(decorder teaching forcing[1 step] , context vector[cur_step])                    \n",
    "\n",
    "\n",
    "# When you do tensor slicing, batch dimension is included\n",
    "\n",
    "*Uncomment & run the following code to test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tips tensor slicing\n",
    "# test_in = Input(shape = (Ty,Dy))\n",
    "# test_out = Lambda(lambda x:x[:,4:5,:])(test_in)\n",
    "# test_m = Model(test_in, test_out)\n",
    "# test_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_s = Input(shape = (My,))\n",
    "initial_c = Input(shape = (My,))\n",
    "\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# decoder tfembd (batch, Ty, Dy)\n",
    "# context (batch, 1, 2Mx)\n",
    "concat_tfemd_ctx = Concatenate(axis = -1)\n",
    "\n",
    "outputs = []\n",
    "for t in range(Ty):\n",
    "    \n",
    "    context = one_step_attention(encoder_output, s)\n",
    "    \n",
    "    # convert teaching forcing to (batch, 1, Dy)\n",
    "    tfembd_cur_step = Lambda(lambda x:x[:,t:t+1,:])(decoder_tfembd_input)\n",
    "    \n",
    "    # concat context and decoder input\n",
    "    decoder_final_input = concat_tfemd_ctx([tfembd_cur_step, context])\n",
    "    \n",
    "    o, s, c = decoder_lstm(decoder_final_input ,initial_state=[s,c])\n",
    "    \n",
    "    output = decoder_dense(o)\n",
    "    \n",
    "    outputs.append(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next question: what is 1 output looks like? - it is a vector of size Vy, (batch Vy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dc_in = Input(shape = (Ty,2*Mx + Dy,))\n",
    "# test_out,h,c = decoder_lstm(test_dc_in)\n",
    "# test_out = decoder_dense(test_out)\n",
    "\n",
    "# Model(test_dc_in,test_out).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WTF are you donig ????       \n",
    "\n",
    "All steps are vectorized operations (batch operation)                       \n",
    "But, loops through time dimension, and collection by time with `outputs` list               \n",
    "Therefor, the list `outputs` is of shape (Ty, batch, Vy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_n_permute(x):\n",
    "    '''\n",
    "        Convet a list of tensors into a concrete tensor\n",
    "    '''\n",
    "    \n",
    "    x = K.stack(x)\n",
    "    x = K.permute_dimensions(x, pattern = (1,0,2))\n",
    "    return x\n",
    "\n",
    "stacker = Lambda(stack_n_permute)\n",
    "outputs = stacker(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMT_model = Model(inputs = [encoder_input, decoder_tf_input, initial_s, initial_c], outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMT_model.save('NMT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NMT_model.save_weights('NMT_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
